# ğŸ“ AI Course Assistant â€” Enterpriseâ€‘Grade RAG Pipeline

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![LlamaIndex](https://img.shields.io/badge/LlamaIndex-0.10-EF2D5E?style=for-the-badge)
![Groq](https://img.shields.io/badge/LLM-Groq%20(Llama3)-orange?style=for-the-badge)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-FF4B4B?style=for-the-badge&logo=streamlit)

---

## ğŸ“Œ What This Project Solves
University students often struggle to search large PDF-based course material efficiently. This project delivers a **production-style Retrievalâ€‘Augmented Generation (RAG) system** that answers questions **strictly from academic PDFs**, ensuring **accurate, syllabusâ€‘aligned responses**.

This is **not a toy chatbot** â€” it demonstrates **industryâ€‘relevant system design**, clean separation of concerns, and lowâ€‘latency inference suitable for real deployments.

---

## ğŸ§  Core Highlights

- ğŸ“š **PDFâ€‘Grounded Answers** â€” No hallucinations, responses are retrieved from indexed documents
- âš¡ **Ultraâ€‘Low Latency** â€” Powered by **Groq LPU inference**
- ğŸ§© **Modular Microservices Architecture** â€” Backend & frontend fully decoupled
- ğŸ—‚ï¸ **Persistent Vector Store** â€” Oneâ€‘time indexing, instant restarts
- ğŸ¯ **Curriculumâ€‘Focused** â€” Optimized for *Artificial Intelligence (GTU â€“ Subject Code: 3161608)*

---

## ğŸ—ï¸ System Architecture

The application follows a **Clientâ€“Server architecture** with clear responsibility boundaries.

```mermaid
graph LR
    A[User] -->|Query| B[Streamlit Frontend]
    B -->|HTTP POST| C[FastAPI Backend]
    C -->|Search| D[LlamaIndex Query Engine]
    D -->|Retrieve| E[(Vector Store / Storage)]
    D -->|Context + Prompt| F[Groq API (Llamaâ€‘3)]
    F -->|LLM Response| C
    C -->|JSON| B
```

### ğŸ”‘ Key Technical Decisions

- **FastAPI over Flask**  
  Chosen for async support, automatic OpenAPI docs, and productionâ€‘grade performance.

- **LlamaIndex (not LangChain)**  
  Used for its superior document indexing, chunking, and retrieval abstractions.

- **Persistent Vector Storage**  
  Embeddings are generated once via `ingest.py` and reused across sessions.

- **Groq LPU Inference**  
  Uses `llamaâ€‘3.3â€‘70bâ€‘versatile` for nearâ€‘instant responses.

---

## ğŸ“‚ Project Structure

```bash
RAG_CHATBOT/
â”œâ”€â”€ data/               # Source PDFs (Knowledge Base)
â”œâ”€â”€ storage/            # Persisted Vector Index (Autoâ€‘generated)
â”œâ”€â”€ ingest.py           # PDF ingestion & embedding pipeline
â”œâ”€â”€ main.py             # FastAPI backend (RAG inference)
â”œâ”€â”€ frontend.py         # Streamlit UI
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ .env                # API keys (ignored by git)
â””â”€â”€ README.md           # Documentation
```

---

## ğŸš€ Installation & Setup

### Prerequisites
- Python **3.10+**
- Groq API Key

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/ai-course-assistant.git
cd ai-course-assistant
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# macOS / Linux
source .venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the project root:

```env
GROQ_API_KEY=gsk_your_api_key_here
```

---

## âš¡ Usage Guide

### 1ï¸âƒ£ Data Ingestion (Run Once)

Convert PDFs into vector embeddings:

```bash
python ingest.py
```

ğŸ“Œ This generates the `storage/` directory.

---

### 2ï¸âƒ£ Start Backend API

```bash
uvicorn main:app --reload
```

- API URL: `http://127.0.0.1:8000`
- Swagger Docs: `http://127.0.0.1:8000/docs`

---

### 3ï¸âƒ£ Start Frontend UI

```bash
streamlit run frontend.py
```

- Web App: `http://localhost:8501`

---

## ğŸ”Œ API Reference

### `POST /chat`

Handles user queries using RAG pipeline.

**Request**
```json
{
  "query": "What are the subfields of Artificial Intelligence?"
}
```

**Response**
```json
{
  "response": "Artificial Intelligence includes subfields such as NLP, Game Playing, Expert Systems, and Connectionist Models..."
}
```

---

## ğŸ”® Future Enhancements

- ğŸ³ Docker & Dockerâ€‘Compose deployment
- ğŸ’¾ Chat history with PostgreSQL
- ğŸ” Hybrid Search (BM25 + Vector)
- ğŸ“Š RAG Evaluation using **RAGAS / DeepEval**
- ğŸ” Authentication & multiâ€‘user support

---

## ğŸ‘¨â€ğŸ’» Author

**Memon Mohammad Zaid Mohammad Azaz**  
ğŸ“ B.Tech IT | AI & Data Enthusiast

- GitHub: https://github.com/Zaidmemon78
- LinkedIn: www.linkedin.com/in/zaid-memon-analyst


---

â­ If this project helped you, consider giving it a star!

